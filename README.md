
# Sign Language Detection

This project implements a basic Sign Language Detection system using a webcam. It collects image data for signs, creates a dataset, trains a classifier, and performs real-time inference.

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/                 # Contains folders (0,1,2,3...) with webcam images for training
â”œâ”€â”€ collect_imgs.py       # Script to collect images using a webcam
â”œâ”€â”€ create_dataset.py     # Processes collected images into a usable dataset
â”œâ”€â”€ train_classifier.py   # Trains a classifier model
â”œâ”€â”€ inference_classifier.py # Performs real-time inference using the trained model
â”œâ”€â”€ model.p               # Trained model file
â”œâ”€â”€ data.pickle           # Serialized dataset
â”œâ”€â”€ requirements.txt      # List of Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ License               # Licensing information
```

## âš™ï¸ Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/sign-language-detection.git
   cd sign-language-detection
   ```

2. Create a virtual environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate  # or venv\Scripts\activate on Windows
   pip install -r requirements.txt
   ```

## ğŸ“¸ Data Collection

Use `collect_imgs.py` to capture images using your webcam:
```bash
python collect_imgs.py
```

Images will be stored in `data/` in folders like `0`, `1`, etc., each representing a different sign/class.

## ğŸ› ï¸ Training

Generate a dataset and train the model:
```bash
python create_dataset.py
python train_classifier.py
```

## ğŸ¯ Inference

Run the live prediction:
```bash
python inference_classifier.py
```

## ğŸ“„ License

This project is licensed under the MIT License. See the `License` file for more details.
